{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58d8f149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import PyPDF2\n",
    "from os import listdir\n",
    "\n",
    "#Ham doi ten tu cac FileFail thanh File cu                    \n",
    "def getFileFail(name, listfile):\n",
    "    for i in listfile:\n",
    "        if i[12:16] == name[4:8]: return i\n",
    "    return False\n",
    "\n",
    "#DS 616 file pdf ban dau\n",
    "list_files = listdir(r'C:\\Users\\an\\Desktop\\New folder')\n",
    "#DS cac file pdf khong co du lieu ban dau\n",
    "list_filesN = listdir(r'C:\\Users\\an\\Desktop\\NewFile')\n",
    "\n",
    "\n",
    "# File chua 420 file pdf lay lan 1\n",
    "File = open('successFile1.txt').read().split('\\n')[:-1]\n",
    "\n",
    "# File chua 126 file pdf lay lan 2\n",
    "FileFail = open('successFileFail.txt').read().split('\\n')[:-1]\n",
    "# File chua 126 file pdf lay lan 2 da dc doi ten\n",
    "newFile = []\n",
    "for i in FileFail:\n",
    "    newFile.append(getFileFail(i, list_files))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a5d4233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ham lay text de kiem tra\n",
    "def Text(path, num):\n",
    "    a = r'C:\\Users\\an\\Desktop\\New folder\\{}'.format(path)\n",
    "    file = open(a, 'rb')\n",
    "    fileReader = PyPDF2.PdfFileReader(file)\n",
    "    page = fileReader.getPage(num)\n",
    "    text = page.extractText().lower()\n",
    "    newtext = ' '.join(text.strip().split('\\n'))\n",
    "    newtext1 = str(newtext.encode(\"ascii\", \"ignore\"))\n",
    "    return newtext1.strip()\n",
    "#Ham lay text(str) va otext(list) de tach du lieu va ghep lai cau hoan chinh\n",
    "def getText(path, num):\n",
    "    bien = getTittle(path)\n",
    "    text = Text(path, num)[bien[0]:bien[1]]\n",
    "    oText = text.strip().split()\n",
    "    newtext1= ''.join(oText)\n",
    "    return oText, newtext1\n",
    "\n",
    "### loai bo noi dung bi trung o dau va cuoi moi trang.\n",
    "def getTittle(path):\n",
    "    text1 = Text(path, 2)\n",
    "    text2 = Text(path, 3)\n",
    "    if (text1[0] == text2[0]) and (text1[-5:] == text2[-5:]):\n",
    "        for i in range(300):\n",
    "            if(text1[i] != text2[i]):\n",
    "                bien1 = i\n",
    "                break\n",
    "        count = 1\n",
    "        for i in range(-1,-300,-1):\n",
    "            if(text1[i] != text2[i]):\n",
    "                if(count == 0):\n",
    "                    bien2 = i\n",
    "                    return bien1, bien2+1\n",
    "                else:\n",
    "                    count-=1\n",
    "    else:\n",
    "        count = 1\n",
    "        for i in range(250):\n",
    "            if(text1[i] != text2[i]):\n",
    "                if(count == 0):\n",
    "                    return i, None\n",
    "                else:\n",
    "                    count-=1\n",
    "                    \n",
    "# tra ve mang chua text khong co khoang trang dung de dua ve text ban dau                    \n",
    "def timMang(mang, text):\n",
    "    for i in range(len(mang)):\n",
    "        if len(''.join(mang[i:])) <= len(text):\n",
    "            return mang[i:]\n",
    "def timMangSau(mang, text):    \n",
    "    for i in range(len(mang)):\n",
    "        if len(''.join(mang[:i])) == len(text):\n",
    "            return mang[:i]\n",
    "        if len(''.join(mang[:i])) >= len(text):\n",
    "            return mang[:i-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f873c785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lay muc luc\n",
    "def getTableOfContentPage(path):\n",
    "    a = r'C:\\Users\\dat\\Desktop\\New folder\\{}'.format(path)\n",
    "    file = open(a, 'rb')\n",
    "    fileReader = PyPDF2.PdfFileReader(file)\n",
    "    pages = fileReader.getNumPages()\n",
    "    for i in range(pages):\n",
    "        page = fileReader.getPage(i)\n",
    "        text = page.extractText().lower()\n",
    "        newtext = ' '.join(text.strip().split('\\n'))\n",
    "        newtext1= ''.join(text.strip().split())\n",
    "        newstr = str(newtext1.encode(\"ascii\", errors='ignore'))\n",
    "#         if \"b'efsascientificreport'\" in newstr or \"b''\" in newstr or \"b'pd'\" in newstr:\n",
    "#             return 1\n",
    "        if 'tableofcontents' in newstr:\n",
    "            return i\n",
    "    return False\n",
    "#Lay trang Thuoc Tinh 2 (TT2)\n",
    "def getImpactHumanPage(path):\n",
    "    a = r'C:\\Users\\dat\\Desktop\\New folder\\{}'.format(path)\n",
    "    file = open(a, 'rb')\n",
    "    fileReader = PyPDF2.PdfFileReader(file)\n",
    "    pages = fileReader.getNumPages()\n",
    "    for i in range(pages):\n",
    "        page = fileReader.getPage(i)\n",
    "        text = page.extractText().lower()\n",
    "        newtext = ' '.join(text.strip().split('\\n'))\n",
    "        newtext1= ''.join(text.strip().split())\n",
    "        newstr = str(newtext1.encode(\"ascii\", errors='ignore'))                \n",
    "        if 'impactonhumanandanimalhealth' in newstr or 'rateandextentofabsorption' in newstr:\n",
    "            return i\n",
    "    return False\n",
    "\n",
    "#Lay noi dung trang muc luc\n",
    "def getTextTOC(path, num):      \n",
    "    oText1, text1 = getText(path, num)\n",
    "    oText2, text2 = getText(path, num+1)\n",
    "    if text2.startswith(\"background\") or text2.startswith(\"ackground\") or text2.startswith(\"ckground\") or text2.startswith(\"commissionregulation\") or text2.startswith('4efsajournal2011;9(7):2300') or text2.startswith('4efsajournal2011;9(7):2299'):\n",
    "        return text1\n",
    "    return text1 + text2\n",
    "\n",
    "def checknum(text):\n",
    "    try:\n",
    "        return int(text[-4:-2])\n",
    "    except:\n",
    "        try:\n",
    "            return int(text[-3:-1])\n",
    "        except:\n",
    "            try:\n",
    "                return int(text[-2:])\n",
    "            except:\n",
    "                try:\n",
    "                    return int(text[-1:])\n",
    "                except:\n",
    "                    return False\n",
    "#Lay so trang chua TT1\n",
    "def getPageTT1(text):\n",
    "    keys1 = ['appendix2', 'appendixb', 'appendixii']\n",
    "\n",
    "    for i in keys1:\n",
    "        array = text.split(i,1)\n",
    "        if len(array) == 2:\n",
    "            return checknum(array[0].strip())\n",
    "    keys2 = ['listofabbreviations']\n",
    "    for i in keys2:\n",
    "        array = text.split(i,1)\n",
    "        if len(array) ==2:\n",
    "            return checknum(array[0].strip())\n",
    "    if 'abbreviations' in text and 'appendix' in text:\n",
    "        array = text.split('appendixa')\n",
    "        return checknum(array[0].strip())\n",
    "                                                                                                         \n",
    "    keys3 = ['laboratorydoseresponsetest',\n",
    "             'residuesrequiringfurtherassessmen',\n",
    "             'preliminaryscreeningdat',\"'efsajournal2013;11(1):3066\",\n",
    "             'worst-caseuse(amongtheeurepresentativeuses):pomefruit(6x0.100kga.s./ha)','monitoring/enforcementmethod']\n",
    "    for i in keys3:\n",
    "        array = text.split(i,1)\n",
    "        if len(array) ==2:\n",
    "            return checknum(array[0].strip())\n",
    "    array = text.split('abbreviations')\n",
    "    if len(array) ==2 :\n",
    "        return checknum(array[0].strip())\n",
    "    return checknum(text.strip())\n",
    "\n",
    "#Lay trang chua background1 (trang bat dau noi dung background)\n",
    "def getPageBackground1(text):\n",
    "    keys1 = ['theactivesubstanceandtheformulatedproduct',\n",
    "            'theidentityofthemicro-organismandthepropertiesoftheformulatedproduct',\n",
    "            'theidentityofthemicroorganismandthepropertiesoftheformulatedproduct',\n",
    "            'theidentityofthemicroorganismsandthepropertiesoftheformulatedproducts',\n",
    "            'conclusionsoftheevaluation']\n",
    "    for i in keys1:\n",
    "        array = text.split(i,1)\n",
    "        if len(array) == 2:\n",
    "            return checknum(array[0].strip())\n",
    "    return False\n",
    "#Lay trang chua background2 (trang ket thuc)\n",
    "def getPageBackground2(text):\n",
    "    keys1 = ['specificconclusionsoftheevaluation',\n",
    "             '1.identity,physical/chemical/technicalpropertiesandmethodsofanalysis', \n",
    "             'conclusionsoftheevaluation','datagaps']\n",
    "    for i in keys1:\n",
    "        array = text.split(i,1)\n",
    "        if len(array) == 2:\n",
    "            return checknum(array[0].strip())\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa7e3fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lay trang muc luc\n",
    "dic = dict()\n",
    "for i in list_files:\n",
    "    page = getTableOfContentPage(i)\n",
    "    if page != False:\n",
    "        dic[i] = page    \n",
    "\n",
    "#Lay noi dung trang muc luc \n",
    "ContentOFTOC = dict()\n",
    "for i in dic:\n",
    "    ContentOFTOC[i] = getTextTOC(i, dic[i])\n",
    "\n",
    "with open('textTOC.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(ContentOFTOC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "73c02199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "35983a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('textTOC.txt')\n",
    "textTOC = json.load(f)\n",
    "\n",
    "newdic1 = dict()\n",
    "nonList = []\n",
    "nonConclu = []\n",
    "for  i in File+newFile:\n",
    "    if 'listofstudiestobegenerated' in textTOC[i]:\n",
    "        bien = textTOC[i].split('listofstudiestobegenerated',1)\n",
    "        if len(bien) == 2:\n",
    "            newdic1[i] = bien[1]\n",
    "        if 'conclusionsandrecommendations' not in textTOC[i]: nonConclu.append(i)\n",
    "    elif 'conclusionsandrecommendations' in textTOC[i]:\n",
    "        nonList.append(i)\n",
    "        bien = textTOC[i].split('conclusionsandrecommendations',1)\n",
    "        if len(bien) == 2:\n",
    "            newdic1[i] = bien[1]\n",
    "    else:\n",
    "        nonList.append(i)\n",
    "        nonConclu.append(i)\n",
    "        bien = textTOC[i].split('concerns',1)\n",
    "        if len(bien) == 2:\n",
    "            newdic1[i] = bien[1]\n",
    "\n",
    "for i in newdic1:\n",
    "    if 'references' in newdic1[i] and 'appendices' in newdic1[i]:\n",
    "        bien = newdic1[i].split('appendi',1)\n",
    "        if len(bien) == 2:\n",
    "            newdic1[i] = bien[0]\n",
    "    elif 'references' in newdic1[i] and 'abbreviations' in newdic1[i]:\n",
    "        bien = newdic1[i].split('abbreviations',1)\n",
    "        if len(bien) == 2:\n",
    "            newdic1[i] = bien[0]\n",
    "    else:\n",
    "        bien = newdic1[i].split('appendi',2)\n",
    "        if len(bien) == 3:\n",
    "            newdic1[i] = bien[0] + bien[1]\n",
    "        else:\n",
    "            bien = newdic1[i].split('abbreviations',1)\n",
    "            if len(bien) == 2:\n",
    "                newdic1[i] = bien[0]\n",
    "page1 = dict()\n",
    "for i in newdic1:\n",
    "    bien = newdic1[i].split('conclusionsandrecommendations', 1)\n",
    "    if len(bien) == 2:\n",
    "        page1[i] = checknum(bien[0])\n",
    "        nonConclu.append(i)\n",
    "    else:\n",
    "        bien = newdic1[i].split('particularconditionsproposedtobetakenintoaccount', 1)\n",
    "        if len(bien) == 2:\n",
    "            page1[i] = checknum(bien[0])\n",
    "            nonConclu.append(i)\n",
    "        else:\n",
    "            bien = newdic1[i].split('1.issuesthatcouldnotbefinalised', 1)\n",
    "            if len(bien) == 2:\n",
    "                check = checknum(bien[0])\n",
    "                if type(check) != int:\n",
    "                    bien = newdic1[i].split('9.1.concernsfortherepresentativeusesevaluated', 1)\n",
    "                    check = checknum(bien[0])\n",
    "                    page1[i] = check\n",
    "                    nonConclu.append(i)\n",
    "                else:    \n",
    "                    page1[i] = checknum(bien[0])\n",
    "                    nonConclu.append(i)\n",
    "            else:\n",
    "                bien = newdic1[i].split('3.concerns', 1)\n",
    "                if len(bien) == 2:\n",
    "                    check = checknum(bien[0])\n",
    "                    if type(check) != int: print(newdic1[i])\n",
    "                    page1[i] = checknum(bien[0])\n",
    "                    nonConclu.append(i)\n",
    "                else:\n",
    "                    bien = newdic1[i].split('issuesthatcouldnotbefinalised', 1)\n",
    "                    if len(bien) == 2:\n",
    "                        check = checknum(bien[0])\n",
    "                        if type(check) != int: print(newdic1[i])\n",
    "                        page1[i] = check\n",
    "                        nonConclu.append(i)\n",
    "                    else:                           \n",
    "                        ######################################################################################################\n",
    "                        bien = newdic1[i].split('1.issuesthatcouldnotbenalised', 1)\n",
    "                        if len(bien) == 2:\n",
    "                            check = checknum(bien[0])\n",
    "                            if type(check) != int: \n",
    "                                bien = newdic1[i].split('9.1.concernsfortherepresentativeusesevaluated', 1)\n",
    "                                check = checknum(bien[0])\n",
    "                                page1[i] = check\n",
    "                                nonConclu.append(i)\n",
    "                            else:\n",
    "                                page1[i] = check\n",
    "                                nonConclu.append(i)\n",
    "                        else:\n",
    "                            bien = newdic1[i].split('9.1issuesthatcouldnotbenalised', 1)\n",
    "                            if len(bien) == 2:\n",
    "                                check = checknum(bien[0])\n",
    "                                if type(check) != int: print(bien[0])\n",
    "                                page1[i] = check\n",
    "                                nonConclu.append(i)\n",
    "                            else:\n",
    "                                bien = newdic1[i].split('10.1.concernsfortherepresentativeusesevaluated', 1)\n",
    "                                if len(bien) == 2:\n",
    "                                    check = checknum(bien[0])\n",
    "                                    if type(check) != int: print(bien[0])\n",
    "                                    page1[i] = check\n",
    "                                    nonConclu.append(i)\n",
    "                                else:    \n",
    "                                    print(i)\n",
    "                                    print(newdic1[i])\n",
    "                                    print('\\n')\n",
    "                                    \n",
    "page2 = dict()\n",
    "for i in newdic1:\n",
    "    check = checknum(newdic1[i])\n",
    "    if type(check) != int:\n",
    "        text = newdic1[i].split('9.3.')[0]\n",
    "        check = checknum(text)\n",
    "        if type(check) == int:\n",
    "            page2[i] = check        \n",
    "        else:\n",
    "            check = checknum(newdic1[i].split('appendixb')[0])\n",
    "            page2[i] = check \n",
    "    else:\n",
    "        page2[i] = check\n",
    "page1['j.efsa.2020.6006.pdf'] = 10    \n",
    "\n",
    "newTT = dict()\n",
    "onewTT = dict()\n",
    "\n",
    "for i in newdic1:\n",
    "    text = ''\n",
    "    otext = []\n",
    "    for j in range(page1[i]-1, page2[i]-1):\n",
    "        bien = getText(i, j)\n",
    "        text+= bien[1]\n",
    "        otext+= bien[0]\n",
    "    newTT[i] = text\n",
    "    onewTT[i] = otext\n",
    "    \n",
    "# with open('newTT.txt', 'w') as convert_file:\n",
    "#      convert_file.write(json.dumps(bien))\n",
    "# with open('onewTT.txt', 'w') as convert_file:\n",
    "#      convert_file.write(json.dumps(obien))\n",
    "\n",
    "listList = []\n",
    "listConclu = []\n",
    "listConcern = []\n",
    "\n",
    "f = open('newTT.txt')\n",
    "bien = json.load(f)\n",
    "f1 = open('onewTT.txt')\n",
    "obien = json.load(f1)\n",
    "\n",
    "for i in File + newFile:\n",
    "    if i in nonConclu:\n",
    "        if i in nonList:\n",
    "            listList.append(None)\n",
    "            listConclu.append(None)\n",
    "            listConcern.append(' '.join(obien[i]))\n",
    "        else:\n",
    "            array = bien[i].split('criticalareasofconcern', 1)\n",
    "            if len(array) == 2:\n",
    "                listConclu.append(None)\n",
    "                listList.append(' '.join(timMangSau(obien[i], array[0])))\n",
    "                listConcern.append(' '.join(timMang(obien[i], array[1])))\n",
    "            else:\n",
    "                array = bien[i].split('concerns', 1)\n",
    "                if len(array) == 2:\n",
    "                    listConclu.append(None)\n",
    "                    listList.append(' '.join(timMangSau(obien[i], array[0])))\n",
    "                    listConcern.append(' '.join(timMang(obien[i], array[1])))\n",
    "                else:\n",
    "                    if i == 'j.efsa.2010.1526.pdf':\n",
    "                        array = bien[i].split(\"uses.'the\")\n",
    "                        listConclu.append(None)\n",
    "                        listList.append(' '.join(timMangSau(obien[i], array[0])) + 'uses.')\n",
    "                        listConcern.append(\"the\" +' '.join(timMang(obien[i], array[1])))\n",
    "                    if i == 'j.efsa.2010.1708.pdf':\n",
    "                        array = bien[i].split(\"operations.\")\n",
    "                        listConclu.append(None)\n",
    "                        listList.append(' '.join(timMangSau(obien[i], array[0])) + 'operations.')\n",
    "                        listConcern.append(' '.join(timMang(obien[i], array[1])))\n",
    "    else:\n",
    "        if i in nonList:\n",
    "            print(i)\n",
    "        else:\n",
    "            array = bien[i].split('criticalareasofconcern', 1)\n",
    "            if len(array) == 2:\n",
    "                listConcern.append(' '.join(timMang(obien[i], array[1])))                \n",
    "                text = array[0]\n",
    "                otext = timMangSau(obien[i], array[0])\n",
    "                array = text.split('conclusionsandrecommendations')\n",
    "                if len(array) == 2:\n",
    "                    listConclu.append(' '.join(timMang(otext, array[1])))\n",
    "                    listList.append(' '.join(timMangSau(otext, array[0])))\n",
    "                else:\n",
    "                    array = text.split('onclusionsandrecommendations')\n",
    "                    if len(array) == 2:\n",
    "                        listConclu.append(' '.join(timMang(otext, array[1])))\n",
    "                        listList.append(' '.join(timMangSau(otext, array[0])))\n",
    "                    else:\n",
    "                        array = text.split('onthebasis')\n",
    "                        listConclu.append(\"the conclusion was reached on the basis\" + ' '.join(timMang(otext, array[1])))\n",
    "                        listList.append(' '.join(timMangSau(otext, array[0])))\n",
    "            else:\n",
    "                array = bien[i].split('riticalareasofconcern', 1)\n",
    "                if len(array) == 2:\n",
    "                    if i == 'j.efsa.2005.102r.pdf':\n",
    "                        listConcern.append(' '.join(timMang(obien[i], array[1])).split('8. 8')[0])\n",
    "                    else:\n",
    "                        listConcern.append(' '.join(timMang(obien[i], array[1])))\n",
    "                    text = array[0]\n",
    "                    otext = timMangSau(obien[i], array[0])\n",
    "                    array = text.split('conclusionsandrecommendations')\n",
    "                    if len(array) == 2:\n",
    "                        listConclu.append(' '.join(timMang(otext, array[1])))\n",
    "                        listList.append(' '.join(timMangSau(otext, array[0])))\n",
    "                    else:\n",
    "                        array = text.split('onclusionsandrecommendations')\n",
    "                        if len(array) == 2:\n",
    "                            listConclu.append(' '.join(timMang(otext, array[1])))\n",
    "                            listList.append(' '.join(timMangSau(otext, array[0])))\n",
    "                else:\n",
    "                    listConcern.append(None)\n",
    "                    array = bien[i].split('conclusionsandrecommendations')\n",
    "                    if len(array) == 2:\n",
    "                        if i == 'j.efsa.2007.103r.pdf':\n",
    "                            listConclu.append(' '.join(timMang(obien[i], array[1])).split('critical areas of conc')[0])\n",
    "                            listList.append(' '.join(timMangSau(obien[i], array[0])))\n",
    "                        else:\n",
    "                            listConclu.append(' '.join(timMang(obien[i], array[1])))\n",
    "                            listList.append(' '.join(timMangSau(obien[i], array[0])))\n",
    "import pandas as pd\n",
    "xong = {\n",
    "    'ten': File+newFile,\n",
    "    'tt1': listList,\n",
    "    'tt2': listConclu,\n",
    "    'tt3': listConcern\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(list(zip(File+newFile, listList, listConclu, listConcern))\n",
    "                           , columns=['Name', 'List of studies to be generated', 'Conclusions and Recommendations', 'Concerns'])\n",
    "df.to_csv('data10-8.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "62499f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9c90f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lay so trang của Data can tim\n",
    "f = open('textTOC.txt')\n",
    "textTOC = json.load(f)\n",
    "\n",
    "pageTT1 = dict()\n",
    "\n",
    "for i in File:\n",
    "    check = getPageTT1(textTOC[i])\n",
    "    if check != False:\n",
    "        pageTT1[i] = check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae6f32a",
   "metadata": {},
   "source": [
    "# Get content of TT1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "877767e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lấy text chứa TT1\n",
    "# Nếu dùng lấy dữ liệu trong list File thì lấy trang từ list pageTT1\n",
    "\n",
    "ContentOfTT1 = dict()\n",
    "oContentOfTT1 = dict()\n",
    "for i in File:\n",
    "    try:\n",
    "        trang1 = getText(i, pageTT1[i]-1)\n",
    "        trang2 = getText(i, pageTT1[i])\n",
    "        trang3  = getText(i, pageTT1[i]+1)\n",
    "    except:\n",
    "        print(i)\n",
    "    if 'molecularformula' in trang3[1] or 'identityofrelevantimpurities' in trang3[1]:\n",
    "        oContentOfTT1[i] =  trang1[0] + trang2[0] + trang3[0]\n",
    "        ContentOfTT1[i] =  trang1[1] + trang2[1] + trang3[1]\n",
    "\n",
    "    elif 'molecularformula' in trang2[1] or 'identityofrelevantimpurities' in trang2[1]:\n",
    "        oContentOfTT1[i] =  trang1[0] + trang2[0]\n",
    "        ContentOfTT1[i] =  trang1[1] + trang2[1]\n",
    "    else:\n",
    "        oContentOfTT1[i] = trang1[0]\n",
    "        ContentOfTT1[i] = trang1[1]\n",
    "\n",
    "with open('textTT1.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(ContentOfTT1))\n",
    "with open('otextTT1.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(oContentOfTT1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394bdcd0",
   "metadata": {},
   "source": [
    "# Tách text chứa TT1 thành 2 phần TT1_1 và TT1_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c4b1512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tach1(text):\n",
    "    keys = ['identity(annexiia,point1)','chemicalname(iupac)','chemicalname']\n",
    "    for i in keys:\n",
    "        array = text.split(i,1)\n",
    "        if len(array) == 2:\n",
    "            return array\n",
    "    return False\n",
    "\n",
    "f = open('textTT1.txt')\n",
    "textTT1 = json.load(f)\n",
    "\n",
    "f1 = open('otextTT1.txt')\n",
    "otextTT1 = json.load(f1)\n",
    "\n",
    "\n",
    "textTT1_1 = dict()\n",
    "otextTT1_1 = dict()\n",
    "\n",
    "textTT1_2 = dict()\n",
    "otextTT1_2 = dict()\n",
    "\n",
    "for i in File:\n",
    "    if i == 'j.efsa.2012.2520.pdf':\n",
    "        array = textTT1[i].split('chemicalname(iupac)',1)\n",
    "        textTT1_1[i] = array[0]\n",
    "        otextTT1_1[i] = timMangSau(otextTT1[i], array[0])\n",
    "        \n",
    "        textTT1_2[i] = array[1]\n",
    "        otextTT1_2[i] = timMang(otextTT1[i], array[1])\n",
    "\n",
    "        continue\n",
    "    check = tach1(textTT1[i])\n",
    "    if check == False:\n",
    "        textTT1_1[i] = textTT1[i]\n",
    "        otextTT1_1[i] = otextTT1[i]\n",
    "        \n",
    "        textTT1_2[i] = None\n",
    "        otextTT1_2[i] = None\n",
    "\n",
    "    else:\n",
    "        textTT1_1[i] = check[0]\n",
    "        otextTT1_1[i] = timMangSau(otextTT1[i], check[0])\n",
    "        \n",
    "        textTT1_2[i] = check[1]\n",
    "        otextTT1_2[i] = timMang(otextTT1[i], check[1])\n",
    "        \n",
    "with open('textTT1_1.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(textTT1_1))\n",
    "with open('otextTT1_1.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(otextTT1_1))\n",
    "\n",
    "with open('textTT1_2.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(textTT1_2))\n",
    "with open('otextTT1_2.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(otextTT1_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5dfe89",
   "metadata": {},
   "source": [
    "# Lấy text chứa TT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a564298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lay text chua nhom Thuoc Tinh 2 (TT2)\n",
    "\n",
    "textTT2 = dict()\n",
    "otextTT2 = dict()\n",
    "\n",
    "for i in File:\n",
    "    check = getImpactHumanPage(i)\n",
    "    if check == False:\n",
    "        textTT2[i] = None\n",
    "        otextTT2[i] = None\n",
    "    else:\n",
    "        bien1 = getText(i,check)\n",
    "        bien2 = getText(i,check+1)\n",
    "#         bien3 = getText(i,check+2)\n",
    "#         if 'ld50' in bien3[1] or 'lc50' in bien3[1] or 'eyeirritation' in bien3[1]:\n",
    "#             otextTT2[i] = bien1[0] + bien2[0] + bien3[0]\n",
    "#             textTT2[i] = bien1[1] + bien2[1] + bien3[1]\n",
    "        if 'ld50' in bien2[1] or 'lc50' in bien2[1] or 'eyeirritation' in bien2[1]:\n",
    "            otextTT2[i] = bien1[0] + bien2[0]\n",
    "            textTT2[i] = bien1[1] + bien2[1]\n",
    "        else:\n",
    "            otextTT2[i] = bien1[0]\n",
    "            textTT2[i] = bien1[1]\n",
    "\n",
    "with open('textTT2.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(textTT2))\n",
    "with open('otextTT2.txt', 'w') as convert_file:\n",
    "    convert_file.write(json.dumps(otextTT2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b6ce1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "HMPage = dict()\n",
    "fail = []\n",
    "for i in File:\n",
    "    check = getImpactHumanPage(i)\n",
    "    if check == False:\n",
    "        fail.append(i)\n",
    "    else:\n",
    "        HMPage[i] = check\n",
    "MAPage = dict()\n",
    "for i in HMPage:\n",
    "    for j in range(HMPage[i]-1, HMPage[i]-6,-1):\n",
    "        text = getText(i, j)[1]\n",
    "        keys = ['technicala.s.(analyticaltechnique)','technicalas(principleofmethod)', 'technicalas(analyticaltechnique)', 'technicala.s.(principleofmethod)','technicalas(principleofthemethod)']\n",
    "        for k in keys:\n",
    "            if k in text:\n",
    "                MAPage[i] = j\n",
    "                break\n",
    "            \n",
    "for i in HMPage:\n",
    "    if i not in MAPage:\n",
    "        for j in range(HMPage[i], 0,-1):\n",
    "            text = getText(i, j)[1]\n",
    "            if 'bodyfluidsandtissues' in text:\n",
    "                bien = j\n",
    "            if 'methodsofanalysis' in text or 'analyticalmethodsfortheactivesubstance' in text or 'technicala.s.' in text or 'technicalas' in text:\n",
    "                MAPage[i] = j\n",
    "                HMPage[i] = bien+1\n",
    "                break\n",
    "                \n",
    "for i in HMPage:\n",
    "    if i not in MAPage: fail.append(i)\n",
    "        \n",
    "for i in MAPage:\n",
    "    if HMPage[i] - MAPage[i] > 5:\n",
    "        fail.append(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed44b000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "for i in MAPage:\n",
    "    if HMPage[i] == MAPage[i]: \n",
    "        print(i in fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f65b7bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = dict()\n",
    "otext = dict()\n",
    "for i in File:\n",
    "    bien1 = ''\n",
    "    bien2 = []\n",
    "    if i in fail:\n",
    "        text[i] = None\n",
    "        otext[i] = None\n",
    "    else:\n",
    "        if HMPage[i] == MAPage[i]: \n",
    "            text[i] = None\n",
    "            otext[i] = None\n",
    "        else:\n",
    "            for j in range(MAPage[i], HMPage[i]):\n",
    "                trang = getText(i, j)\n",
    "                bien1+=trang[1]\n",
    "                bien2+=trang[0]\n",
    "            text[i] = bien1\n",
    "            otext[i] = bien2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4b39ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9efefe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('12-8text.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(text))\n",
    "with open('12-8otext.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(otext))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6ca3eb",
   "metadata": {},
   "source": [
    "# Lấy text Summary của 420 file đầu và 126 file sau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2867b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GetSumMary tu trang dau den trang muc luc\n",
    "\n",
    "summary = dict()\n",
    "osummary = dict()\n",
    "for i in File:\n",
    "    text = ''\n",
    "    mang = []\n",
    "#biến dic là dict() chứa trang mục lục (int)\n",
    "    for j in range(dic[i]):\n",
    "        bien1 = getText(i, j)\n",
    "        text += bien1[1]\n",
    "        mang += bien1[0]\n",
    "    summary[i] = text\n",
    "    osummary[i] = mang\n",
    "\n",
    "with open('summary.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(summary))\n",
    "with open('osummary.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(osummary))\n",
    "\n",
    "summaryFail = dict()\n",
    "osummaryFail = dict()\n",
    "for i in newFile:\n",
    "    text = ''\n",
    "    mang = []\n",
    "    for j in range(dic[i]):\n",
    "        bien1 = getText(i, j)\n",
    "        text += bien1[1]\n",
    "        mang += bien1[0]\n",
    "    summaryFail[i] = text\n",
    "    osummaryFail[i] = mang\n",
    "\n",
    "# with open('summaryFail.txt', 'w') as convert_file:\n",
    "#      convert_file.write(json.dumps(summaryFail))\n",
    "# with open('osummaryFail.txt', 'w') as convert_file:\n",
    "#      convert_file.write(json.dumps(osummaryFail))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d867659",
   "metadata": {},
   "source": [
    "# Lấy text Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3017d784",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################## lấy background 420 file đầu\n",
    "\n",
    "pageBackground1 = dict()\n",
    "for i in File:\n",
    "    text = textTOC[i]  \n",
    "    bien = getPageBackground1(text)\n",
    "    if bien != False:\n",
    "        pageBackground1[i] = bien\n",
    "        \n",
    "pageBackground2 = dict()\n",
    "for i in File:\n",
    "    text = textTOC[i]  \n",
    "    bien = getPageBackground2(text)\n",
    "    if bien != False:\n",
    "        pageBackground2[i] = bien\n",
    "        \n",
    "background = dict()\n",
    "obackground = dict()\n",
    "\n",
    "for i in File:\n",
    "    text = ''\n",
    "    mang = []\n",
    "    for j in range(pageBackground1[i]-1, pageBackground2[i]):\n",
    "        try:\n",
    "            bien = getText(i, j)\n",
    "        except:\n",
    "            print(i, j)\n",
    "            continue\n",
    "        text += bien[1]\n",
    "        mang += bien[0]\n",
    "    background[i] = text\n",
    "    obackground[i] = mang\n",
    "    \n",
    "with open('background.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(background))\n",
    "with open('obackground.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(obackground))\n",
    "\n",
    "######################################################################### 126 file sau\n",
    "        \n",
    "pageBackground2Fail = dict()\n",
    "for i in newFile:\n",
    "    text = textTOC[i]  \n",
    "    bien = getPageBackground2(text)\n",
    "    if bien != False:\n",
    "        pageBackground2Fail[i] = bien\n",
    "        \n",
    "backgroundFail = dict()\n",
    "obackgroundFail = dict()\n",
    "\n",
    "for i in newFile:\n",
    "    text = ''\n",
    "    mang = []\n",
    "    for j in range(dic[i]+1, pageBackground2Fail[i]):\n",
    "        try:\n",
    "            bien = getText(i, j)\n",
    "        except:\n",
    "            print(bien, j)\n",
    "        text += bien[1]\n",
    "        mang += bien[0]\n",
    "    backgroundFail[i] = text\n",
    "    obackgroundFail[i] = mang\n",
    "    \n",
    "with open('backgroundFail.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(backgroundFail))\n",
    "with open('obackgroundFail.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(obackgroundFail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38731048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTCuoi = []\n",
    "\n",
    "# def getTTcuoi(path, num):\n",
    "#     text = ''\n",
    "#     for i in range(num):\n",
    "#         text += getText(path, i)[1]\n",
    "#     if 'concernsarenotidenti' in text:\n",
    "#         return 'Concerns are not identified'            \n",
    "#     elif 'concernsareidenti' in text:\n",
    "#         return 'Concerns are identified'\n",
    "\n",
    "# for i in File+newFile:\n",
    "#     check = getTTcuoi(i, dic[i])\n",
    "#     TTCuoi.append(check)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
