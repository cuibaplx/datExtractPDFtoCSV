{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58d8f149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import PyPDF2\n",
    "from os import listdir\n",
    "\n",
    "#Ham doi ten tu cac FileFail thanh File cu                    \n",
    "def getFileFail(name, listfile):\n",
    "    for i in listfile:\n",
    "        if i[12:16] == name[4:8]: return i\n",
    "    return False\n",
    "\n",
    "#DS 616 file pdf ban dau\n",
    "list_files = listdir(r'C:\\Users\\an\\Desktop\\New folder')\n",
    "#DS cac file pdf khong co du lieu ban dau\n",
    "list_filesN = listdir(r'C:\\Users\\an\\Desktop\\NewFile')\n",
    "\n",
    "\n",
    "# File chua 420 file pdf lay lan 1\n",
    "File = open('successFile1.txt').read().split('\\n')[:-1]\n",
    "\n",
    "# File chua 126 file pdf lay lan 2\n",
    "FileFail = open('successFileFail.txt').read().split('\\n')[:-1]\n",
    "# File chua 126 file pdf lay lan 2 da dc doi ten\n",
    "newFile = []\n",
    "for i in FileFail:\n",
    "    newFile.append(getFileFail(i, list_files))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a5d4233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ham lay text de kiem tra\n",
    "def Text(path, num):\n",
    "    a = r'C:\\Users\\dat\\Desktop\\New folder\\{}'.format(path)\n",
    "    file = open(a, 'rb')\n",
    "    fileReader = PyPDF2.PdfFileReader(file)\n",
    "    page = fileReader.getPage(num)\n",
    "    text = page.extractText().lower()\n",
    "    newtext = ' '.join(text.strip().split('\\n'))\n",
    "    newtext1 = str(newtext.encode(\"ascii\", \"ignore\"))\n",
    "    return newtext1.strip()\n",
    "#Ham lay text(str) va otext(list) de tach du lieu va ghep lai cau hoan chinh\n",
    "def getText(path, num):\n",
    "    bien = getTittle(path)\n",
    "    text = Text(path, num)[bien[0]:bien[1]]\n",
    "    oText = text.strip().split()\n",
    "    newtext1= ''.join(oText)\n",
    "    return oText, newtext1\n",
    "\n",
    "### loai bo noi dung bi trung o dau va cuoi moi trang.\n",
    "def getTittle(path):\n",
    "    text1 = Text(path, 2)\n",
    "    text2 = Text(path, 3)\n",
    "    if (text1[0] == text2[0]) and (text1[-5:] == text2[-5:]):\n",
    "        for i in range(300):\n",
    "            if(text1[i] != text2[i]):\n",
    "                bien1 = i\n",
    "                break\n",
    "        count = 1\n",
    "        for i in range(-1,-300,-1):\n",
    "            if(text1[i] != text2[i]):\n",
    "                if(count == 0):\n",
    "                    bien2 = i\n",
    "                    return bien1, bien2+1\n",
    "                else:\n",
    "                    count-=1\n",
    "    else:\n",
    "        count = 1\n",
    "        for i in range(250):\n",
    "            if(text1[i] != text2[i]):\n",
    "                if(count == 0):\n",
    "                    return i, None\n",
    "                else:\n",
    "                    count-=1\n",
    "                    \n",
    "# tra ve mang chua text khong co khoang trang dung de dua ve text ban dau                    \n",
    "def timMang(mang, text):\n",
    "    for i in range(len(mang)):\n",
    "        if len(''.join(mang[i:])) <= len(text):\n",
    "            return mang[i:]\n",
    "def timMangSau(mang, text):    \n",
    "    for i in range(len(mang)):\n",
    "        if len(''.join(mang[:i])) == len(text):\n",
    "            return mang[:i]\n",
    "        if len(''.join(mang[:i])) >= len(text):\n",
    "            return mang[:i-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f873c785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lay muc luc\n",
    "def getTableOfContentPage(path):\n",
    "    a = r'C:\\Users\\dat\\Desktop\\New folder\\{}'.format(path)\n",
    "    file = open(a, 'rb')\n",
    "    fileReader = PyPDF2.PdfFileReader(file)\n",
    "    pages = fileReader.getNumPages()\n",
    "    for i in range(pages):\n",
    "        page = fileReader.getPage(i)\n",
    "        text = page.extractText().lower()\n",
    "        newtext = ' '.join(text.strip().split('\\n'))\n",
    "        newtext1= ''.join(text.strip().split())\n",
    "        newstr = str(newtext1.encode(\"ascii\", errors='ignore'))\n",
    "#         if \"b'efsascientificreport'\" in newstr or \"b''\" in newstr or \"b'pd'\" in newstr:\n",
    "#             return 1\n",
    "        if 'tableofcontents' in newstr:\n",
    "            return i\n",
    "    return False\n",
    "#Lay trang Thuoc Tinh 2 (TT2)\n",
    "def getImpactHumanPage(path):\n",
    "    a = r'C:\\Users\\dat\\Desktop\\New folder\\{}'.format(path)\n",
    "    file = open(a, 'rb')\n",
    "    fileReader = PyPDF2.PdfFileReader(file)\n",
    "    pages = fileReader.getNumPages()\n",
    "    for i in range(pages):\n",
    "        page = fileReader.getPage(i)\n",
    "        text = page.extractText().lower()\n",
    "        newtext = ' '.join(text.strip().split('\\n'))\n",
    "        newtext1= ''.join(text.strip().split())\n",
    "        newstr = str(newtext1.encode(\"ascii\", errors='ignore'))                \n",
    "        if 'impactonhumanandanimalhealth' in newstr or 'rateandextentofabsorption' in newstr:\n",
    "            return i\n",
    "    return False\n",
    "\n",
    "#Lay noi dung trang muc luc\n",
    "def getTextTOC(path, num):      \n",
    "    oText1, text1 = getText(path, num)\n",
    "    oText2, text2 = getText(path, num+1)\n",
    "    if text2.startswith(\"background\") or text2.startswith(\"ackground\") or text2.startswith(\"ckground\") or text2.startswith(\"commissionregulation\") or text2.startswith('4efsajournal2011;9(7):2300') or text2.startswith('4efsajournal2011;9(7):2299'):\n",
    "        return text1\n",
    "    return text1 + text2\n",
    "\n",
    "def checknum(text):\n",
    "    try:\n",
    "        return int(text[-4:-2])\n",
    "    except:\n",
    "        try:\n",
    "            return int(text[-3:-1])\n",
    "        except:\n",
    "            try:\n",
    "                return int(text[-2:])\n",
    "            except:\n",
    "                try:\n",
    "                    return int(text[-1:])\n",
    "                except:\n",
    "                    return False\n",
    "#Lay so trang chua TT1\n",
    "def getPageTT1(text):\n",
    "    keys1 = ['appendix2', 'appendixb', 'appendixii']\n",
    "\n",
    "    for i in keys1:\n",
    "        array = text.split(i,1)\n",
    "        if len(array) == 2:\n",
    "            return checknum(array[0].strip())\n",
    "    keys2 = ['listofabbreviations']\n",
    "    for i in keys2:\n",
    "        array = text.split(i,1)\n",
    "        if len(array) ==2:\n",
    "            return checknum(array[0].strip())\n",
    "    if 'abbreviations' in text and 'appendix' in text:\n",
    "        array = text.split('appendixa')\n",
    "        return checknum(array[0].strip())\n",
    "                                                                                                         \n",
    "    keys3 = ['laboratorydoseresponsetest',\n",
    "             'residuesrequiringfurtherassessmen',\n",
    "             'preliminaryscreeningdat',\"'efsajournal2013;11(1):3066\",\n",
    "             'worst-caseuse(amongtheeurepresentativeuses):pomefruit(6x0.100kga.s./ha)','monitoring/enforcementmethod']\n",
    "    for i in keys3:\n",
    "        array = text.split(i,1)\n",
    "        if len(array) ==2:\n",
    "            return checknum(array[0].strip())\n",
    "    array = text.split('abbreviations')\n",
    "    if len(array) ==2 :\n",
    "        return checknum(array[0].strip())\n",
    "    return checknum(text.strip())\n",
    "\n",
    "#Lay trang chua background1 (trang bat dau noi dung background)\n",
    "def getPageBackground1(text):\n",
    "    keys1 = ['theactivesubstanceandtheformulatedproduct',\n",
    "            'theidentityofthemicro-organismandthepropertiesoftheformulatedproduct',\n",
    "            'theidentityofthemicroorganismandthepropertiesoftheformulatedproduct',\n",
    "            'theidentityofthemicroorganismsandthepropertiesoftheformulatedproducts',\n",
    "            'conclusionsoftheevaluation']\n",
    "    for i in keys1:\n",
    "        array = text.split(i,1)\n",
    "        if len(array) == 2:\n",
    "            return checknum(array[0].strip())\n",
    "    return False\n",
    "#Lay trang chua background2 (trang ket thuc)\n",
    "def getPageBackground2(text):\n",
    "    keys1 = ['specificconclusionsoftheevaluation',\n",
    "             '1.identity,physical/chemical/technicalpropertiesandmethodsofanalysis', \n",
    "             'conclusionsoftheevaluation','datagaps']\n",
    "    for i in keys1:\n",
    "        array = text.split(i,1)\n",
    "        if len(array) == 2:\n",
    "            return checknum(array[0].strip())\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa7e3fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lay trang muc luc\n",
    "dic = dict()\n",
    "for i in list_files:\n",
    "    page = getTableOfContentPage(i)\n",
    "    if page != False:\n",
    "        dic[i] = page    \n",
    "\n",
    "#Lay noi dung trang muc luc \n",
    "ContentOFTOC = dict()\n",
    "for i in dic:\n",
    "    ContentOFTOC[i] = getTextTOC(i, dic[i])\n",
    "\n",
    "with open('textTOC.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(ContentOFTOC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c90f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lay so trang của Data can tim\n",
    "f = open('textTOC.txt')\n",
    "textTOC = json.load(f)\n",
    "\n",
    "pageTT1 = dict()\n",
    "\n",
    "for i in File:\n",
    "    check = getPageTT1(textTOC[i])\n",
    "    if check != False:\n",
    "        pageTT1[i] = check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae6f32a",
   "metadata": {},
   "source": [
    "# Get content of TT1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "877767e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lấy text chứa TT1\n",
    "# Nếu dùng lấy dữ liệu trong list File thì lấy trang từ list pageTT1\n",
    "\n",
    "ContentOfTT1 = dict()\n",
    "oContentOfTT1 = dict()\n",
    "for i in File:\n",
    "    try:\n",
    "        trang1 = getText(i, pageTT1[i]-1)\n",
    "        trang2 = getText(i, pageTT1[i])\n",
    "        trang3  = getText(i, pageTT1[i]+1)\n",
    "    except:\n",
    "        print(i)\n",
    "    if 'molecularformula' in trang3[1] or 'identityofrelevantimpurities' in trang3[1]:\n",
    "        oContentOfTT1[i] =  trang1[0] + trang2[0] + trang3[0]\n",
    "        ContentOfTT1[i] =  trang1[1] + trang2[1] + trang3[1]\n",
    "\n",
    "    elif 'molecularformula' in trang2[1] or 'identityofrelevantimpurities' in trang2[1]:\n",
    "        oContentOfTT1[i] =  trang1[0] + trang2[0]\n",
    "        ContentOfTT1[i] =  trang1[1] + trang2[1]\n",
    "    else:\n",
    "        oContentOfTT1[i] = trang1[0]\n",
    "        ContentOfTT1[i] = trang1[1]\n",
    "\n",
    "with open('textTT1.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(ContentOfTT1))\n",
    "with open('otextTT1.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(oContentOfTT1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394bdcd0",
   "metadata": {},
   "source": [
    "# Tách text chứa TT1 thành 2 phần TT1_1 và TT1_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c4b1512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tach1(text):\n",
    "    keys = ['identity(annexiia,point1)','chemicalname(iupac)','chemicalname']\n",
    "    for i in keys:\n",
    "        array = text.split(i,1)\n",
    "        if len(array) == 2:\n",
    "            return array\n",
    "    return False\n",
    "\n",
    "f = open('textTT1.txt')\n",
    "textTT1 = json.load(f)\n",
    "\n",
    "f1 = open('otextTT1.txt')\n",
    "otextTT1 = json.load(f1)\n",
    "\n",
    "\n",
    "textTT1_1 = dict()\n",
    "otextTT1_1 = dict()\n",
    "\n",
    "textTT1_2 = dict()\n",
    "otextTT1_2 = dict()\n",
    "\n",
    "for i in File:\n",
    "    if i == 'j.efsa.2012.2520.pdf':\n",
    "        array = textTT1[i].split('chemicalname(iupac)',1)\n",
    "        textTT1_1[i] = array[0]\n",
    "        otextTT1_1[i] = timMangSau(otextTT1[i], array[0])\n",
    "        \n",
    "        textTT1_2[i] = array[1]\n",
    "        otextTT1_2[i] = timMang(otextTT1[i], array[1])\n",
    "\n",
    "        continue\n",
    "    check = tach1(textTT1[i])\n",
    "    if check == False:\n",
    "        textTT1_1[i] = textTT1[i]\n",
    "        otextTT1_1[i] = otextTT1[i]\n",
    "        \n",
    "        textTT1_2[i] = None\n",
    "        otextTT1_2[i] = None\n",
    "\n",
    "    else:\n",
    "        textTT1_1[i] = check[0]\n",
    "        otextTT1_1[i] = timMangSau(otextTT1[i], check[0])\n",
    "        \n",
    "        textTT1_2[i] = check[1]\n",
    "        otextTT1_2[i] = timMang(otextTT1[i], check[1])\n",
    "        \n",
    "with open('textTT1_1.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(textTT1_1))\n",
    "with open('otextTT1_1.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(otextTT1_1))\n",
    "\n",
    "with open('textTT1_2.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(textTT1_2))\n",
    "with open('otextTT1_2.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(otextTT1_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5dfe89",
   "metadata": {},
   "source": [
    "# Lấy text chứa TT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a564298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lay text chua nhom Thuoc Tinh 2 (TT2)\n",
    "\n",
    "textTT2 = dict()\n",
    "otextTT2 = dict()\n",
    "\n",
    "for i in File:\n",
    "    check = getImpactHumanPage(i)\n",
    "    if check == False:\n",
    "        textTT2[i] = None\n",
    "        otextTT2[i] = None\n",
    "    else:\n",
    "        bien1 = getText(i,check)\n",
    "        bien2 = getText(i,check+1)\n",
    "#         bien3 = getText(i,check+2)\n",
    "#         if 'ld50' in bien3[1] or 'lc50' in bien3[1] or 'eyeirritation' in bien3[1]:\n",
    "#             otextTT2[i] = bien1[0] + bien2[0] + bien3[0]\n",
    "#             textTT2[i] = bien1[1] + bien2[1] + bien3[1]\n",
    "        if 'ld50' in bien2[1] or 'lc50' in bien2[1] or 'eyeirritation' in bien2[1]:\n",
    "            otextTT2[i] = bien1[0] + bien2[0]\n",
    "            textTT2[i] = bien1[1] + bien2[1]\n",
    "        else:\n",
    "            otextTT2[i] = bien1[0]\n",
    "            textTT2[i] = bien1[1]\n",
    "\n",
    "with open('textTT2.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(textTT2))\n",
    "with open('otextTT2.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(otextTT2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6ca3eb",
   "metadata": {},
   "source": [
    "# Lấy text Summary của 420 file đầu và 126 file sau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2867b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GetSumMary tu trang dau den trang muc luc\n",
    "\n",
    "summary = dict()\n",
    "osummary = dict()\n",
    "for i in File:\n",
    "    text = ''\n",
    "    mang = []\n",
    "#biến dic là dict() chứa trang mục lục (int)\n",
    "    for j in range(dic[i]):\n",
    "        bien1 = getText(i, j)\n",
    "        text += bien1[1]\n",
    "        mang += bien1[0]\n",
    "    summary[i] = text\n",
    "    osummary[i] = mang\n",
    "\n",
    "with open('summary.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(summary))\n",
    "with open('osummary.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(osummary))\n",
    "\n",
    "summaryFail = dict()\n",
    "osummaryFail = dict()\n",
    "for i in newFile:\n",
    "    text = ''\n",
    "    mang = []\n",
    "    for j in range(dic[i]):\n",
    "        bien1 = getText(i, j)\n",
    "        text += bien1[1]\n",
    "        mang += bien1[0]\n",
    "    summaryFail[i] = text\n",
    "    osummaryFail[i] = mang\n",
    "\n",
    "with open('summaryFail.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(summaryFail))\n",
    "with open('osummaryFail.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(osummaryFail))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d867659",
   "metadata": {},
   "source": [
    "# Lấy text Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3017d784",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################## lấy background 420 file đầu\n",
    "\n",
    "pageBackground1 = dict()\n",
    "for i in File:\n",
    "    text = textTOC[i]  \n",
    "    bien = getPageBackground1(text)\n",
    "    if bien != False:\n",
    "        pageBackground1[i] = bien\n",
    "        \n",
    "pageBackground2 = dict()\n",
    "for i in File:\n",
    "    text = textTOC[i]  \n",
    "    bien = getPageBackground2(text)\n",
    "    if bien != False:\n",
    "        pageBackground2[i] = bien\n",
    "        \n",
    "background = dict()\n",
    "obackground = dict()\n",
    "\n",
    "for i in File:\n",
    "    text = ''\n",
    "    mang = []\n",
    "    for j in range(pageBackground1[i]-1, pageBackground2[i]):\n",
    "        try:\n",
    "            bien = getText(i, j)\n",
    "        except:\n",
    "            print(i, j)\n",
    "            continue\n",
    "        text += bien[1]\n",
    "        mang += bien[0]\n",
    "    background[i] = text\n",
    "    obackground[i] = mang\n",
    "    \n",
    "with open('background.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(background))\n",
    "with open('obackground.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(obackground))\n",
    "\n",
    "######################################################################### 126 file sau\n",
    "        \n",
    "pageBackground2Fail = dict()\n",
    "for i in newFile:\n",
    "    text = textTOC[i]  \n",
    "    bien = getPageBackground2(text)\n",
    "    if bien != False:\n",
    "        pageBackground2Fail[i] = bien\n",
    "        \n",
    "backgroundFail = dict()\n",
    "obackgroundFail = dict()\n",
    "\n",
    "for i in newFile:\n",
    "    text = ''\n",
    "    mang = []\n",
    "    for j in range(dic[i]+1, pageBackground2Fail[i]):\n",
    "        try:\n",
    "            bien = getText(i, j)\n",
    "        except:\n",
    "            print(bien, j)\n",
    "        text += bien[1]\n",
    "        mang += bien[0]\n",
    "    backgroundFail[i] = text\n",
    "    obackgroundFail[i] = mang\n",
    "    \n",
    "with open('backgroundFail.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(backgroundFail))\n",
    "with open('obackgroundFail.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(obackgroundFail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38731048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTCuoi = []\n",
    "\n",
    "# def getTTcuoi(path, num):\n",
    "#     text = ''\n",
    "#     for i in range(num):\n",
    "#         text += getText(path, i)[1]\n",
    "#     if 'concernsarenotidenti' in text:\n",
    "#         return 'Concerns are not identified'            \n",
    "#     elif 'concernsareidenti' in text:\n",
    "#         return 'Concerns are identified'\n",
    "\n",
    "# for i in File+newFile:\n",
    "#     check = getTTcuoi(i, dic[i])\n",
    "#     TTCuoi.append(check)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
